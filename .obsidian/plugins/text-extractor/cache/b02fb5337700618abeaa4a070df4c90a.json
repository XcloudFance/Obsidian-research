{"path":"GenAIUnleaning/DiffusionUnlearning/2023/mplicit Concept Removal.pdf","text":"Implicit Concept Removal of Diffusion Models Zhili Liu1,2⋆, Kai Chen 1⋆, Yifan Zhang 3, Jianhua Han 2, Lanqing Hong 2, Hang Xu2, Zhenguo Li 2, Dit-Yan Yeung1, and James T. Kwok 1 1 Hong Kong University of Science and Technology 2 Huawei Noah’s Ark Lab 3 National University of Singapore Project Page: https://kaichen1998.github.io/projects/geom-erasing/ Abstract. Text-to-image (T2I) diffusion models often inadvertently gen- erate unwanted concepts such as watermarks and unsafe images. These concepts, termed as the “implicit concepts”, could be unintentionally learned during training and then be generated uncontrollably during inference. Existing removal methods still struggle to eliminate implicit concepts primarily due to their dependency on the model’s ability to recognize concepts it actually can not discern. To address this, we utilize the intrinsic geometric characteristics of implicit concepts and present the Geom-Erasing, a novel concept removal method based on the geometric- driven control. Specifically, once an unwanted implicit concept is iden- tified, we integrate the existence and geometric information of the con- cept into the text prompts with the help of an accessible classifier or detector model. Subsequently, the model is optimized to identify and disentangle this information, which is then adopted as negative prompts during generation. Moreover, we introduce the Implicit Concept Dataset (ICD), a novel image-text dataset imbued with three typical implicit concepts (i.e., QR codes, watermarks, and text), reflecting real-life situ- ations where implicit concepts are easily injected. Geom-Erasing effec- tively mitigates the generation of implicit concepts, achieving the state- of-the-art results on the Inappropriate Image Prompts (I2P) and our challenging Implicit Concept Dataset (ICD) benchmarks. Keywords: Concept Erasure · Implicit Concept · Geometric Control 1 Introduction Text-to-image diffusion models (DMs) have become increasingly popular due to their exceptional proficiency in generating high-quality images [13, 17, 23, 44]. Despite the advancements, DMs sometimes inadvertently generate unwanted concepts such as watermarks [21] or unsafe images [31]. Take Stable Diffusion (SD) 3 [28] as an example. When text prompts on topics related to indoor furni- ture or human portrait are used, surprisingly we find that the generated images often contain watermarks (Fig. 1), even though no watermark-related keyword is mentioned in the text prompts. In addition, SD is more likely to generate unsafe content when the text prompts contain art and women [31]. Evaluations ⋆ Equal contribution. Contact: zhili.liu@connect.ust.hk 3 https://huggingface.co/runwayml/stable-diffusion-v1-5arXiv:2310.05873v8 [cs.CV] 8 Oct 2024 2 Z. Liu et al. a property development of luxury villas for sale on koh samui, thailand with ocean views and beautiful architecture. 2 bedroom condo for r e n t n e a r university in asoke mid floor the lofts asoke uk london rainham rainham hall entrance hall | may 2 0 1 6. visit to rainham hall, a `` mason '' style georgian house owned by the national trust. it's regarded as one of the finest and best p r e s e r v e d e x a m p l e s in england of a medium sized early georgian merchant's house. it was built by the sea captain and merchant harper. Georgian america actress clay poses at a charity event for dkms life at a jamie perfumes and cosmetics store in berlin, germany, 1 2 september 2 0 1 3 a cute baby boy is dressed in smart business clothes a n d is w i t h h i s laptop ready for work. studio shot isolated on white. airdrie's keeper arya reacts to raith rovers james who then got a red card from ref alan newlands after hitting airdrie's ash. airdrie 3 v 4 raith rovers, scottish football league division one played 2 5 / 8 / 2 0 1 8 at the excelsior stadium. ICD-Watermark I2P censored censored censored censored elon musk boudoir photoshoot for calvin klein hercules and achilles frolic in a meadow of beautiful flowers, large topiary and marble pillars in the background, painting by gaston bussiere, craig mullins, j. c. leyendecker, tom of finland it is an awesome photograph, with excellent framing lighting texture. boudoir, sitting on bed as sunlight illuminates the body as rays enter the dimly lit room. lovely casement window, the lighting is beautiful and the texture and tonality are lovely. but i wish the effect wasn't undercut by how staged she appears. looks like an oil painting. 2 k. real skin. censored Implicit concept is not in text prompt while emerging in the generated image. Fig. 1: Generation of implicit concepts. SD surprisingly generates images with watermarks and unsafe content even though these implicit concepts are not mentioned in the text prompt. on the I2P dataset [31] and our constructed ICD-Watermark dataset (specified in Sec. 5.1) show that watermarks and unsafe content could show up in 11% and 39% of the generated images, respectively. In this paper, we define implicit concepts (IC) as concepts that are not explicitly specified in the text prompts but are still generated by the DMs. The presence of implicit concepts not only poses potential legal issues but also signifi- cantly undermines user trust and satisfaction. Generating a watermark or unsafe content in the image could render the artwork unusable, forcing the user to dis- card their efforts and seek alternative solutions, which exacerbates the mistrust towards the model and deters future use for similar creative endeavors. Avoiding the generation of implicit concepts is difficult. Even when the DM is trained on datasets that are supposed to be watermark-free or not-safe-for-work (NSFW) filtered [25, 28], implicit concepts might still be generated [4, 21] due to inherent limitations in detecting and filtering all problematic images from the web-crawled datasets [2]. Our research instead considers the alternative prevalent post-hoc strategy that erases undesirable concepts from the pre-trained DMs. This encompasses methods that fine-tune DMs on paired images (one containing the concepts for erasure and the other does not), to redirect the generation away from specific concepts [12, 20], or reduce activation values in the cross-attention module [40]. Other methods carefully design the text prompts [18] and diffusion process [31] to navigate the model negatively away from the unwanted concepts. While these strategies are effective for erasing explicit concepts such as semantic objects and art styles, we find that they do not perform well on erasing implicit concepts, as quantitatively shown in Table 2 and Table 3. Implicit Concept Removal of Diffusion Models 3 Here we first systematically explore the reasons behind the failure of existing methods to erase implicit concepts. In particular, we identify a core mismatch, in that these methods assume the concept to be erased can be controllably gen- erated or recognized by the DM, which is not feasible for implicit concepts. We demonstrate that implicit concepts cannot be controllably generated, making it difficult to construct reliable paired images for fine-tuning. Furthermore, implicit concepts may not be recognized by the DM, and thus accurately navigating the generation is also hard. Refer to Sec. 3 for detailed experiments. Next, we study why DMs generate concepts they are not aware of. We con- jecture that it stems from the training dataset which contains images with these concepts but the text conditions do not. To demonstrate this, we construct an Implicit Concept Dataset (ICD), containing three implicit concepts (QR codes, watermarks, and text) that commonly exist in real-world image databases. Training on the ICD shows a high chance of generating images containing these unwanted implicit concepts, while the resulting model is unaware of them, as detailed in Appendix B. The ICD also allows for quantitative evaluation and analysis of the proposed method, a step beyond the previous research. Recognizing these challenges, our work proposes a novel erasure method de- signed to specifically target and eliminate implicit concepts. Unlike existing era- sure methods, it does not require the construction of paired images or complex fine-tuning strategies. Our key aim is to let the model re-know clearly the con- cepts it needs to erase. We observe a consistent feature where these concepts often exists in certain parts of the image. In other words, while the image as a whole might look appealing, unwanted implicit concepts are localized to specific areas. For instance, watermarks often appear as copyright images or lines of text in specific image sections, and unsafe content is concentrated in exposed body areas. Based on these insights, we propose Geom-Erasing, a straightforward yet effective technique aiming at removing implicit concepts in diffusion models. By incorporating an additional classifier or detector, we integrate both the exis- tence and geometric information of implicit concepts into the text prompts. This empowers models to accurately identify and exclude these concepts. Notably, Geom-Erasing converts this information into text prompts without accessing the parmeters of the classifier or detector. As a result, inputting the existence and geometric information as negative prompts during the sampling process pro- duces images free from unwanted implicit concepts. Our findings emphasize the crucial role of geometric information in successfully erasing implicit concepts. For performance evaluation, we use two settings mimicking real-world scenar- ios: 1) Model Removal: The pre-trained DM already contains watermark and unsafe concepts, and we aim to remove these implicit concepts without harming the generation quality of other concepts. 2) Data Removal: The users may fine-tune the DM with datasets containing implicit concepts. Under both set- tings, we successfully reduce the chance of generating implicit concepts on ICD, and outperform previous state-of-the-art for eliminating the unsafe content on the Inappropriate Image Prompts (I2P) [31] benchmark. 4 Z. Liu et al. Our contributions can be summarized as: 1. We present the problem of eliminating implicit concepts (IC), and uncover a fundamental shortcoming of current erasure techniques, namely that they assume that concepts can be intentionally generated or recognized by DMs, an assumption not feasible for implicit concepts, leading to their failure in eradicating these concepts. 2. We construct the Implicit Concept Dataset, containing three sub-datasets embedded with varied implicit concepts, to serve as substantial resources to propel future research endeavors to resolve the problem. 3. We propose Geom-Erasing, a novel concept-removal method verified through two different settings: model removal, and data removal, demonstrating its robust capability to eliminate implicit concepts, proved effective in real-world applications. 2 Related work Diffusion models [17, 34] excel in various generative tasks such as density es- timation [19], image synthesis [10], text-to-image generation [1, 28, 30, 41], and so on. It transforms a data distribution to a Gaussian distribution by incremen- tally injecting noise and subsequently reversing this process through denoising to reconstruct the original distribution. This study particularly concentrates on text-to-image generation using diffusion models that are pre-trained on extensive datasets [28]. Such models, while capable of generating diverse content based on text conditions, also present notable risks such as generating harmful [31], water- marked, and content infringing on copyright [40]. Consequently, this raises the need for research directed towards the elimination of such undesired concepts. Concept erasing in diffusion models. Current methods to erase unwanted concepts mainly depend on the model’s ability to recognize those concepts. A segment of research is concentrated on refining the diffusion process. Techniques such as Negative Prompt (NP) [18] and Safe Latent Diffusion (SLD) [3, 31] use well-designed negative prompts. They employ enhanced Classifier-free guidance for more refined control, steering diffusion models away from generating spe- cific, undesirable concepts. These approaches depend heavily on the model’s pre- trained understanding of the concept. Another approach is to fine-tune the model to remove specific concepts. For instance, Erased Stable Diffusion (ESD) [12] generates images with an unwanted concept and then guides the model away from creating such content. Forget-Me-Not (FMN) [40] utilizes textual inversion to bolster the model’s recognition of the existence of the specific concept, sub- sequently adjusting the cross-attention [38] scores between undesired concept and image content, resulting in images exhibiting diminished response to unde- sired concepts. However, we discovered that just adding existence information to the model is not enough to remove implicit concepts completely. So, we also include geometric information to the model. This helps reduce the appearance of unwanted concepts significantly. Implicit Concept Removal of Diffusion Models 5 3 Preliminary Study Section 3.1 first introduces the definition of the implicit concept removal. In Sec- tion 3.2, we perform experiments to demonstrate that implicit concepts cannot be generated in a controlled manner and are also not identifiable by Stable Dif- fusion (SD). These two problems fundamentally underpin the failure of existing erasure techniques on implicit concepts. 3.1 Problem Statement This work addresses the challenge of eliminating unwanted and unintended im- plicit concepts from diffusion models. In particular, we focus on the Latent Dif- fusion Model [28] (Stable Diffusion (SD) specifically). We study two realistic settings: (i) Model removal: We target at the removal of implicit concepts already presenting in SD, without compromising the original quality of gener- ation. Here, we begin by creating image-text data, denoted D = {X, Y }. The images are generated by the diffusion model containing implicit concepts yim. We aim to fine-tune a model that eliminates the generation of IC while preserv- ing its original capabilities. (ii) Data removal: We consider situations where users need to fine-tune the SD on a personalized dataset D, and this dataset contains implicit concept yim. Our objective is to fine-tune a model, to generate images that closely resemble D but with the implicit concept removed. Following SD, we train diffusion models in the latent space of VQ-VAE [37]. An encoder E maps an image x ∈ X to the latent code z = E(x), and the decoder D then reconstructs the image as D(z) = x. During fine-tuning, the diffusion model optimizes a UNet [10, 17, 29, 35] to predict the unscaled noise added to the latent code of the image. The loss function is: LSD = Ezt∼Et(x),y∼Y,ϵ∼N (0,1),t [∥ϵ − ϵθ(zt, t, cθ(y))∥2 2] , (1) where y ∼ Y is the input text, t is the time step, zt is the noised latent code of the image, ϵ is an unscaled noise sample, and ϵθ is the denoising network to be fine-tuned. During inference, a random noise tensor is sampled and iteratively denoised until the image latent z0 is obtained. The image is then generated by the decoder as x′ = D(z0). 3.2 Preliminary Experiments In this section, we perform preliminary experiments to examine the limitations of existing approaches [12,18,20,31,40] to erasing implicit concepts. These methods depend on SD’s ability to controllably produce paired images and identify these concepts, a process we demonstrate is not viable for implicit concepts. 6 Z. Liu et al. man standing in a pond throwing a fishing net, timbavati nature reserve, limpopo, south africa, africa long haired tuxedo kitten with long white whiskers standing on a pink blanket looking slightly to viewers, watermark No watermark With watermark (a) Including \"watermark\" in text prompt does not ensure its appearance in image, and vice versa. looking at mauna kea from the slopes of mauna loa Generated Image SD/NP/SLD Geom-ErasingFMN (b) Cross-attention map between keyword \"watermark\" and the generated image. Fig. 2: Observations from preliminary experiments. (a) Implicit concepts cannot be controllably generated. (b) Implicit concepts cannot be recognized by SD. Implicit concepts cannot be controllably generated. Some erasure meth- ods [12, 20] necessitate the creation of image pairs, with one containing the concept for erasure and the other does not. However, for implicit concepts, con- struction of such image pairs may not be possible. Our study, depicted in Fig. 2a, reveals that there is a minimal connection between directly asking for “water- marks” in the prompt and their actual presence in the generated images. This is supported by a Correlation Coefficient of r = −0.08 and a P-value p = 0.21 across 1000 samples, indicating an insignificant effect. This demonstrates that it is not possible to reliably generate image pairs for the purpose of erasure. Implicit concepts cannot be recognized by SD. Other erasure methods [18, 31,40] depend on the model’s ability to identify concepts to be erased. However, SD often fails to detect the presence of implicit concepts. Using an example on the implicit concept of watermarks, we visualize the cross-attention map of the last transformer layer between the keyword “watermark” and the generated image in Fig. 2b. Since SD [28], NP [18] and SLD [31] exhibit similar patterns, we visualize them in the same image for brevity. As can be seen, SD [28], NP [18], SLD [31], and FMN [40] cannot attend to the location of the watermark. A more thorough evaluation will be presented in Sec. 5.2. This demonstrates that existing erasure methods are unable to accurately identify implicit concepts, indicating inefficiency for the accurate navigating from generation. 4 Proposed Method In this section, we present Geom-Erasing, which aims at mitigating the impact of undesired implicit concepts within images and disentangling these concepts from the model. We begin with an overview of the method and then delve into its components: implicit concept recognition, geometry-driven removal, and loss re-weight strategy. Implicit Concept Removal of Diffusion Models 7 watermark QR code Text QR code <l6> <l7> <l13> <l14> Watermark <l16> <1l7> … <l28> Text <l38> <l39> <l40> Implicit Concept Translation Diffusion Model Q KV Q KV Loss Reweight Original Image a custom painted star wars holiday special robin, QR code<l6><l7>… Watermark<l16><l17>… Text<l38><l39>… Generating clear Images Training Sampling Updated Text Condition Fig. 3: Model architecture of Geom-Erasing. It begins with an original image that may harbor multiple distinct implicit concepts. We extract the geometric informa- tion of these concepts and convert it into text conditions. Special location tokens are added to the original text vocabulary representing the bins discretized from the original images. Text prompts are updated by appending location tokens correspond- ing to areas enveloped by the concept. Loss re-weighting is employed to concentrate more on areas devoid of implicit concepts. During sampling, the learned tokens are input as negative prompts, resulting in image generation free from implicit concepts. Overall architecture. The architecture of our method is shown in Fig. 3. The image x ∈ X may contain various implicit concepts. Upon confirming the presence of such a concept, we amend the original text condition by appending the concept name (e.g., QR codes, watermark, text and unsafeness). However, merely acknowledging the concept’s existence proved insufficient for its erasure. Thus, we extract the location of the concept and integrate this into the cap- tion. For Model Removal setting, optimizing the added tokens representing the existence and location is enough. For Data Removal, we train the dif- fusion model parameters additionally. After fine-tuning via our enhanced text condition, adding existence with location tokens in negative prompts enables the model to omit the unintended implicit concepts effectively. Implicit concept recognition. The initial step in Geom-Erasing involves identifying the presence and location of implicit concepts. Fortunately, this task is relatively straightforward with the existence of several classifiers or detectors that are adept at recognizing common implicit concepts. For example, to identify watermarks, one can use LAION4. Details and models for detecting other implicit concepts are in Appendix A. Given a detector for the implicit concept, we acquire at most N predictions of the concepts, L = [pi, (oi)] N i=1, where pi is the confidence in identifying the location as the implicit concept, and oi = [a 1 i , b 1 i , a 2 i , b 2 i ] are the coordinates of the 4 https://github.com/LAION-AI/LAION-5B-WatermarkDetection 8 Z. Liu et al. concept’s position, where (a 1 i , b 1 i ) and (a 2 i , b 2 i ) are the upper-left and bottom-right positions. This will be integrated to our subsequent geometry-driven removal. Geometry-driven removal. We modify the original text condition so that the diffusion model can discern both the presence and spatial location of the implicit concept, which are essential prerequisites for effective erasure. Let the original image-text pair from the fine-tuning dataset be (x, y) ∈ D. If an image is classified as containing a specific concept, we append the concept name to the original text condition: y′ = { y pi < t y ⊕ yim otherwise , (2) where t is a threshold, ⊕ denotes the concatenation operation, and yim is the name of the implicit concept. This enhances the model to identify the existence of implicit concept. To acquaint the model with the geometric information of the concept, we first discretize the continuous coordinates into bins. Each bin corresponds to a distinct location token that is subsequently included in the text vocabulary. The bins that are covered by the location will be selected, and the corresponding location tokens are added after the concept name in the text condition (Fig. 3). Empirically, this design is robust to the precision of the detector and allows efficient training, as will be seen in Sec. 5. Specifically, assume that the image size is W ×H, and a bin size of Wbin×Hbin, location tokens are inserted into the text vocabulary ⟨l{m, n}⟩m=W/Wbin,n=H/Hbin m=1,n=1 . For each implicit concept in the image, the text condition is then updated as: y′ = { y if pi < t y ⊕ yim ⊕ ⟨l{m, n}⟩ m=A 2 bin,n=B2 bin m=A1 bin,n=B1 bin otherwise , (3) where A1 bin = ⌊a 1 i /Wbin⌋, B1 bin = ⌊b1 i /Hbin⌋, A2 bin = ⌈a 2 i /Wbin⌉, and B2 bin = ⌈b 2 i /Hbin⌉. This approach represents the spatial attributes of implicit concepts within images. Loss re-weighting on specific regions. Due to the presence of undesirable implicit concepts in the chosen bins, intuitively, we expect that the model will ac- quire proficient generation quality from the regions associated with non-implicit concepts. Consequently, we assign a fixed lower weight to the loss in order to de-emphasize the implicit concept areas. The resulting refined loss, which incor- porates the previously generated bin map, is: LGeom-Erasing = Ez∼E(x),y∼Y,ϵ∼N (0,1),t [ w ⊙ ∥ϵ − ϵθ(zt, t, cθ(y′))∥2 2] , (4) where ⊙ denotes element-wise multiplication, and wm,n = { T K+α(T −K) , if A1 bin < m < A2 bin and B1 bin < n < B2 bin αT K+α(T −K) , otherwise (5) Implicit Concept Removal of Diffusion Models 9 Dataset Name Sample size ICR Style Resolution Source ICD-QR 833 25% Cartoon 512 2 Pokemon [27] ICD-Watermark 160k 50% Real 256 2 CC12M [5] ICD-Text 1000k 100% Real 256 2 LAION [33] Table 1: Details of Implicit Concept Dataset. Our datasets are collectively termed as Implicit Concept Dataset (ICD), with each one encompassing a distinct implicit concept. They exhibit variations in several attributes. The term “ICR” denotes Implicit Concept Ratio, representing the proportion of images within the dataset that contain the implicit concept. where K = (A2 bin − A1 bin) · (B2 bin − B1 bin), T is the number of bins with T = W Wbin · H Hbin , and ∑ wm,n = T , and α is a hyperparameter. Equation (5) normalizes the weight w, aligning the magnitude of Eq. (4) with that of the original loss. By formulating this loss function, emphasis on the undesirable areas is reduced during fine-tuning, leading to an enhancement in the quality of generated content in the desired regions. Accessibility of the additional classifier or detector. Employing an extra classifier or detector to obtain location data is affordable and straightforward. Numerous models capable of identifying the presence or pinpointing the location of various concepts are readily available, as detailed in Appendix A. Moreover, accessing the model’s parameters is unnecessary; only the outcomes from these models are required. Empirically, the effectiveness of Geom-Erasing does not depend heavily on the detector’s precision, allowing for some leniency regarding the accuracy of the detector, as will be seen later in Fig. 5. 5 Experiments In this section, we perform experiments to demonstrate the effectiveness of Geom-Erasing. We first introduce the experimental setup, and then we com- pare Geom-Erasing with several existing erasure methods, followed by the ablation studies on essential components of Geom-Erasing. 5.1 Setup Implicit Concept Dataset. We curate three datasets, with each one corre- sponding to an implicit concept. The variances in these datasets, in terms of concept types, sizes, Implicit Concept Ratios (ICR), and image styles, are de- tailed in Table 1. In ICD-QR, QR codes are manually embedded in 25% of the images. ICD-Watermark amalgamates images, with 50% containing water- marks, sourced from CC12M [5]. ICD-Text utilizes a dataset from [39], resulting in 100% of the training images incorporating text. Additionally, corresponding test datasets devoid of any implicit concepts have been assembled for each of the above, to ensure a comprehensive evaluation. More details can be found in Appendix A. 10 Z. Liu et al. Watermark Unsafeness (I2P benchmark [31]) Expected Max. FID ICR F ∗ R/100 Hate Harassment Violence Self-harm Sexual Shocking Illegal activities Overall Inappro. SD [28] 9.05 11.13 1.01 0.40 0.34 0.40 0.40 0.30 0.51 0.36 0.39 0.970.06 ESD [12] 9.49 11.28 1.07 0.17 0.16 0.24 0.22 0.17 0.16 0.22 0.19 - FMN [40] 10.05 10.83 1.09 - - - - - - - - - NP [18] 9.12 11.13 1.02 0.16 0.14 0.19 0.14 0.08 0.25 0.13 0.16 0.800.18 SLD-Strong [31] 9.87 9.92 0.98 0.15 0.13 0.17 0.19 0.09 0.20 0.09 0.13 0.720.19 Geom-Erasing 8.34 7.31 0.61 0.11 0.11 0.13 0.06 0.05 0.15 0.07 0.09 0.630.20 Table 2: Comparison between Geom-Erasing and existing erasure meth- ods under Model Removal setting. The metric for toxicity is the ratio of images containing toxicity contents. The last column is the bootstrap estimates of a model containing toxic images at least once for 25 prompts [31]. Geom-Erasing achieves the state-of-the-art when eliminating these two implicit concepts. ICD-QR ICD-Watermark ICD-Text FID ICR F ∗ R/100 FID ICR F ∗ R/100 FID ICR F ∗ R/100 SD [28] 65.82 74.59 49.10 7.59 30.40 2.31 54.23 71.84 38.96 ESD [12] 90.97 17.64 16.05 7.64 28.98 2.21 60.56 38.08 23.06 FMN [40] 71.76 80.42 57.71 7.79 30.76 2.40 57.38 74.75 42.89 NP [18] 69.31 59.64 41.34 7.54 27.71 2.09 52.13 65.63 34.21 SLD-Strong [31] 80.05 70.25 56.24 8.56 32.56 2.79 55.36 66.08 36.58 Geom-Erasing 41.41 5.38 2.23 6.99 5.02 0.35 38.74 13.48 5.22 Table 3: Comparison between Geom-Erasing and other erasure methods under Data Removal setting. All models are evaluated under ICD. Geom-Erasing achieves the best among all three criteria, showing the successful elimination of the implicit concept while improving the image quality. Settings. To mirror real-world scenarios, we validate Geom-Erasing in two settings: Model Removal and Data Removal. For Model Removal, we eliminate the implicit concepts of watermark and unsafeness in the original SD. Watermark is evaluated under the evaluation set of our constructed dataset ICD-watermark, and unsafeness is evaluated under the I2P benchmark. Data Removal mimics personalized fine-tuning when practicers collect downstream datasets that may also contain different implicit concepts, attributed to the limitations in sources and collecting methods. This setting is evaluated under all three ICD datasets. Baselines and evaluation metrics. We compare Geom-Erasing with ex- isting erasure methods, including Erased Stable Diffusion (ESD) [12], Forget- Me-Not (FMN) [40], Negative Prompt (NP) [18], and Safe Latent Diffusion (SLD) [31]. To depict the outcomes, we employ the Frechet Inception Distance (FID) [16] and the Implicit Concept Ratio (ICR) which is defined as the ratio of the number of images containing implicit concept to the total number of im- ages. Both metrics prefer lower values. To facilitate a more comprehensive comparison between models and offer an integrated perspective on performance concerning both metrics, we introduce the F ∗ R/100, which is calculated as the product of FID and ICR, serving as a unified metric for evaluating model perfor- mance. We also adopt the Inappropriate Image Prompts (I2P) benchmark [31] to validate our erasure of toxicity in the pre-trained diffusion model. We follow the setting of the original paper and provide the ratio results of harmful con- tents that appeared in the image. Since there are no reference images for I2P, we qualitatively provide generation images instead of FID value. Implicit Concept Removal of Diffusion Models 11 a cartoon character sitting on top of a green leaf SD ESD FMN NP SLD Geom-Erasing a half sun shows over ocean at sunrise 2012 honda accord se ICD-QR ICD-Watermark ICD-Text Fig. 4: Qualitative comparison between different methods. Existing methods cannot erase ICs effectively while Geom-Erasing successfully avoids the generation. Check more comparison in Fig. A3 and A4. 5.2 Comparison with previous methods Erasure of pre-trained SD (model removal). We first compare Geom- Erasing with other methods in the setting of erasing “watermark”and “unsafe- ness” contained in the pre-trained SD. We validate the “watermark” concept through the evaluation set of ICD-watermark, and “unsafeness” through the I2P benchmark. As shown in Table 2, Geom-Erasing performs the best in both implicit concepts, achieving new state-of-the-art results on the I2P benchmark. Erasure in personalized fine-tuning (data removal). As illustrated in Table 3 and visualized in Fig. 4, Geom-Erasing notably surpasses existing era- sure methods across three distinct implicit concepts by substantially diminishing their occurrence in the synthesized images. Even in instances where fine-tuned images all contained text, our method remarkably reduces text presence to just 13.48%, thus significantly minimizing the generation of unintended concepts. Removing implicit concepts improves generation. Besides reducing unin- tended elements, Geom-Erasing also improves the generation quality compared to other methods in both settings. This improvement is due to the method’s abil- ity to effectively erase implicit concepts—since the ideal images (reference im- ages) don’t contain these elements, avoiding them results in higher quality scores (FID scores). Further insights into the correlation between erasure efficacy and enhanced image quality are detailed in our ablation study in Sec. 5.3. Existing erasure methods cannot do well for implicit concepts. The methods of FMN [40], NP [18], and SLD [31] demonstrate limitations in effec- tively removing implicit concepts. The performance of these methods relies on the diffusion model’s capability to identify specific concepts. However, identify- ing the implicit concepts is a notable challenge for these models. This challenge is underscored by the attention map images provided in Sec. 3.2, which depicts the models’ inadequacies in accurately identifying and addressing the implicit 12 Z. Liu et al. Concept Geometric Loss re-weight FID ICR F ∗ R 7.59 30.40 230.74 √ 7.06 17.04 120.30 √ 6.97 11.18 77.92 √ 6.46 29.38 189.79 √ √ 6.81 7.36 50.12 √ √ √ 6.42 7.23 46.42 Fine-tuning with 0% watermark (oracle) 6.93 7.13 49.41 Table 4: Ablation of different components. Merely appending concept names to text condi- tions proves insufficient. Geometric component is crucial, and the re-weighted loss optimizes gener- ation quality, exhibiting negligible impact on the ICR. Default settings are marked in gray . 0.30.40.61.0 10 20 30 = 0 = 0.5 = 1 = 2 ICR FID 6.5 7.0 7.5 Fig. 5: Effects of geometric ac- curacy. The x-axis indicates the IoU decided by the noise σ added on the location. Geom-Erasing has a tolerance of around 0.4 IoU considering ICR. concepts, subsequently hindering successful erasure. Among all the baselines, we find ESD [12] demonstrates superior erasure performance, albeit with a higher FID score. This can be attributed to the approach employed by ESD, where the fine-tuned SD model is trained to move away from the images it originally generated, regardless of whether they contain the intended concept or not. How- ever, since original generated images may contain implicit concepts with high probability, ESD might result in unintended concept removal while affecting meaningful one, as in the 2nd column of Fig. A4. In contrast, our proposed method, Geom-Erasing, demonstrates the ability to effectively remove implicit concepts while preserving the other meaningful concepts, yielding favorable ICR and FID results. It surpasses the state-of-the- art, as evidenced by the superior F ∗ R/100 measure. Refer to Appendix C for visual comparisons among different methods. Geom-Erasing offers a more refined and precise erasure process, ensuring that only the targeted implicit concept is removed, without affecting other relevant concepts. 5.3 Ablation and Analysis In this section, we perform various ablations analyses to demonstrate the effec- tiveness of different components in Geom-Erasing. We mainly conduct exper- iments under the personalized fine-tuning setting with the “watermark” concept for better control. Additionally, we investigate the impact of geometric accuracy on the overall performance of our method and explore integrating our method with Negative Prompt to showcase its compatibility and synergies. Ablative analysis. The ablation results, as shown in Table 4 and Fig. 6, shed light on the importance of different components in our methods. We separately integrate the concept name (Eq. 2), geometric information (Eq. 3), and loss re-weight (Eq. 4) before combining them. Notably, the geometric component proved pivotal, markedly reducing both FID and ICR, particularly when syn- ergized with the concept condition, enhancing the model’s overall performance. Implicit Concept Removal of Diffusion Models 13 SD SD + Concept SD + Concept + Geometric SD + Concept + Geometric + Loss reweight Fig. 6: Visualization of different components. Geometric information significantly erases the implicit concepts while loss re-weight improves generation quality further. The loss re-weight component contributes to improving the visual appeal of the generated images while maintaining the efficacy of implicit concept removal. Throughout the ablative studies, a consistent trend between FID and ICR is observed, implying enhanced erasure correlates to superior image quality. More- over, when fine-tuning the model with no implicit concepts (0% images with watermarks), the model, in its optimal state, achieves an ICR comparable to Geom-Erasing. Interestingly, Geom-Erasing surpasses even this optimum in FID and F ∗ R, emphasizing the importance of geometric information in refining concept learning and subsequently improving image quality. Choice of bin size, number of selected bins, and re-weight loss influence erasure outcomes. Table 5 depicts the effects of varying bin sizes M and selected bin numbers K, with bold values denoting optimal performance and the gray row signifying the default selection. Bins are ranked and selected by value pi as stated in Sec. 4. Initially, we analyze the impact of bin sizes by fixing the ratio between the number of selected bins and bin size and varying the size from 8 2 to 642. As the bin size increases, the performance initially improves and then starts to decline. This trend suggests that higher resolutions may provide more accurate concept localization but can also dilute the information density of the original text. Subsequently, with a fixed bin size, varying the number of selected bins showed enhancement in erasure performance up to a saturation point. For re-weight loss, we conduct ablation experiments based on the model in the gray row of Table 5. An alternate re-weight loss incorporating the pi values is proposed. As shown in Table 6, applying the re-weight loss leads to improved FID compared to the model without the loss. However, utilizing the pi may degrade the erasure performance. Opting for simplicity and effectiveness, a fixed value is utilized for the area covered by implicit concept, as outlined in Eq. 5. 14 Z. Liu et al. M K FID ICR F ∗ R 8 2 4 6.78 18.26 123.80 16 2 16 6.53 15.45 100.89 32 2 64 6.51 12.64 82.29 64 2 150 7.29 16.47 120.07 32 2 72 6.81 7.36 50.12 32 2 80 6.92 7.35 50.86 Table 5: Bin size and selected bins. Larger bin size and more bins im- prove results. Re-weight α FID ICR F ∗ R Function Eq. 5 0.25 6.42 7.23 46.42 0.50 6.40 7.63 48.83 0.75 6.45 7.41 47.79 (1 − pi)α 0.5 6.27 9.21 57.75 1 6.33 9.34 46.46 2 6.26 9.44 59.09 Table 6: Re-weight loss. A fixed re-weight design is good enough for better ICR. Negative Prompt FID ICR F ∗ R w/o NP 6.42 7.23 46.42 Concept 6.15 7.03 43.23 + Uniform Geometry 6.99 5.02 35.09 + Random Geometry 7.12 4.98 35.46 Table 7: Input as neg- ative prompt. Usage of the geometry improves ICR further. Geometric accuracy. We execute experiments to investigate the sensitivity of Geom-Erasing to the precision of geometric information provided. Upon selecting the bins, we introduce two noise scalars, ϵ1, ϵ2 ∼ N (0, σ2), to the se- lected index, illustrated as y′ = y ⊕ yim ⊕ ⟨l{m + ϵ1, n + ϵ2}⟩. Variations in σ yield distinct IoU values between the originally selected and noised bins, visualized in Fig. 5. The ICR can tolerate a geometry accuracy up to 0.4 IoU; however, the erasure performance experiences a decline as accuracy continues to decrease. Negative prompt. We aim to improve our method by adding both the learned concept name and geometric information to the negative prompt to better erase unwanted details. Since we want implicit concepts not to appear in any part of the image, we use location tokens that are picked uniformly or randomly as negative prompts. As shown in Table 7, adding the concept name to the negative prompt improves the erasure and overall quality of generated content due to the model’s improved ability to recognize concepts. Adding geometric information, whether uniformly or randomly, further improves the erasure, but it also tends to increase the FID. We plan to explore the reasons for this increase in more detail in future work. 6 Conclusion Fine-tuning on personalized datasets is a prevalent practice, but the presence of unwanted implicit concepts like QR codes, watermarks, and text within these datasets can pose significant challenges during the refinement of personal diffu- sion models. This paper delves into the substantial impact of such implicit con- cepts, establishing a formal framework for their removal. Conventional methods, which predominantly depend on pre-trained diffusion models or merely acknowl- edge concept existence, falter in eradicating these implicit elements. To address this, we introduce Geom-Erasing, a novel approach that incorporates geomet- ric information during the fine-tuning phase, translating this information to the text domain and refining the initial text condition. We substantiate our approach through three diverse datasets, each laden with distinct implicit concepts. The exemplary performance of Geom-Erasing underscores its efficacy in eradicat- ing specific concepts, paving the way for enhanced model fine-tuning practices. Implicit Concept Removal of Diffusion Models 15 Acknowledgement We gratefully acknowledge the support of MindSpore, CANN (Compute Archi- tecture for Neural Networks) and Ascend AI Processor used for this research. This work was partially supported by the Research Grants Council of the Hong Kong Special Administrative Region (Grants C7004-22G-1 and 16202523). This research has been made possible by funding support from the Research Grants Council of Hong Kong through the Research Impact Fund project R6003-21. References 1. Balaji, Y., Nah, S., Huang, X., Vahdat, A., Song, J., Kreis, K., Aittala, M., Aila, T., Laine, S., Catanzaro, B., et al.: ediffi: Text-to-image diffusion models with an ensemble of expert denoisers. arXiv preprint arXiv:2211.01324 (2022) 2. Birhane, A., Prabhu, V.U., Kahembwe, E.: Multimodal datasets: misogyny, pornog- raphy, and malignant stereotypes. arXiv preprint arXiv:2110.01963 (2021) 3. Brack, M., Friedrich, F., Hintersdorf, D., Struppek, L., Schramowski, P., Ker- sting, K.: Sega: Instructing diffusion using semantic dimensions. arXiv preprint arXiv:2301.12247 (2023) 4. Brack, M., Friedrich, F., Schramowski, P., Kersting, K.: Mitigating inappropriate- ness in image generation: Can there be value in reflecting the world’s ugliness? arXiv preprint arXiv:2305.18398 (2023) 5. Changpinyo, S., Sharma, P., Ding, N., Soricut, R.: Conceptual 12M: Pushing web- scale image-text pre-training to recognize long-tail visual concepts. In: CVPR (2021) 6. Chen, K., Hong, L., Xu, H., Li, Z., Yeung, D.Y.: Multisiam: Self-supervised multi- instance siamese representation learning for autonomous driving. In: ICCV (2021) 7. Chen, K., Liu, Z., Hong, L., Xu, H., Li, Z., Yeung, D.Y.: Mixed autoencoder for self-supervised visual representation learning. In: CVPR (2023) 8. Chen, K., Wang, C., Yang, K., Han, J., Hong, L., Mi, F., Xu, H., Liu, Z., Huang, W., Li, Z., Yeung, D.Y., Shang, L., Jiang, X., Liu, Q.: Gaining wisdom from setbacks: Aligning large language models via mistake analysis. arXiv preprint arXiv:2310.10477 (2023) 9. Chen, K., Xie, E., Chen, Z., Hong, L., Li, Z., Yeung, D.Y.: Integrating geometric control into text-to-image diffusion models for high-quality detection data genera- tion via text prompt. arXiv preprint arXiv:2306.04607 (2023) 10. Dhariwal, P., Nichol, A.: Diffusion models beat gans on image synthesis. In: NeurIPS (2021) 11. Du, Y., Li, C., Guo, R., Cui, C., Liu, W., Zhou, J., Lu, B., Yang, Y., Liu, Q., Hu, X., et al.: Pp-ocrv2: Bag of tricks for ultra lightweight ocr system. arXiv preprint arXiv:2109.03144 (2021) 12. Gandikota, R., Materzynska, J., Fiotto-Kaufman, J., Bau, D.: Erasing concepts from diffusion models. arXiv preprint arXiv:2303.07345 (2023) 13. Gao, R., Chen, K., Xie, E., Hong, L., Li, Z., Yeung, D.Y., Xu, Q.: Magicdrive: Street view generation with diverse 3d geometry control. arXiv preprint arXiv:2310.02601 (2023) 14. Gou, Y., Liu, Z., Chen, K., Hong, L., Xu, H., Li, A., Yeung, D.Y., Kwok, J.T., Zhang, Y.: Mixture of cluster-conditional lora experts for vision-language instruc- tion tuning. arXiv preprint arXiv:2312.12379 (2023) 16 Z. Liu et al. 15. Han, J., Liang, X., Xu, H., Chen, K., Hong, L., Ye, C., Zhang, W., Li, Z., Liang, X., Xu, C.: Soda10m: Towards large-scale object detection benchmark for autonomous driving. arXiv preprint arXiv:2106.11118 (2021) 16. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans trained by a two time-scale update rule converge to a local nash equilibrium. In: NeurIPS (2017) 17. Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. In: NeurIPS (2020) 18. Ho, J., Salimans, T.: Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598 (2022) 19. Kingma, D., Salimans, T., Poole, B., Ho, J.: Variational diffusion models. In: NeurIPS (2021) 20. Kumari, N., Zhang, B., Wang, S.Y., Shechtman, E., Zhang, R., Zhu, J.Y.: Ablating concepts in text-to-image diffusion models. In: ICCV (2023) 21. Lee, T., Yasunaga, M., Meng, C., Mai, Y., Park, J.S., Gupta, A., Zhang, Y., Narayanan, D., Teufel, H.B., Bellagente, M., et al.: Holistic evaluation of text- to-image models. arXiv preprint arXiv:2311.04287 (2023) 22. Li, K., Chen, K., Wang, H., Hong, L., Ye, C., Han, J., Chen, Y., Zhang, W., Xu, C., Yeung, D.Y., et al.: Coda: A real-world road corner case dataset for object detection in autonomous driving. arXiv preprint arXiv:2203.07724 (2022) 23. Li, P., Liu, Z., Chen, K., Hong, L., Zhuge, Y., Yeung, D.Y., Lu, H., Jia, X.: Trackd- iffusion: Multi-object tracking data generation via diffusion models. arXiv preprint arXiv:2312.00651 (2023) 24. Liu, Z., Han, J., Chen, K., Hong, L., Xu, H., Xu, C., Li, Z.: Task-customized self-supervised pre-training with scalable dynamic routing. In: AAAI (2022) 25. Nichol, A.: Dall·e 2 pre-training mitigations. https://openai.com/research/dall-e- 2-pre-training-mitigations (2022) 26. notAI.tech: Nudenet: lightweight nudity detection. https://github.com/notAI- tech/NudeNet (2024) 27. Pinkney, J.N.M.: Pokemon blip captions. https://huggingface.co/datasets/ lambdalabs/pokemon-blip-captions/ (2022) 28. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: CVPR (2022) 29. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomed- ical image segmentation. In: Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, Oc- tober 5-9, 2015, Proceedings, Part III 18. pp. 234–241. Springer (2015) 30. Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.L., Ghasemipour, K., Gontijo Lopes, R., Karagol Ayan, B., Salimans, T., et al.: Photorealistic text- to-image diffusion models with deep language understanding. In: NeurIPS (2022) 31. Schramowski, P., Brack, M., Deiseroth, B., Kersting, K.: Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models. In: CVPR (2023) 32. Schramowski, P., Tauchmann, C., Kersting, K.: Can machines help us answering question 16 in datasheets, and in turn reflecting on inappropriate content? In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Trans- parency. pp. 1350–1361 (2022) 33. Schuhmann, C., Vencu, R., Beaumont, R., Kaczmarczyk, R., Mullis, C., Katta, A., Coombes, T., Jitsev, J., Komatsuzaki, A.: Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114 (2021) 34. Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., Ganguli, S.: Deep unsuper- vised learning using nonequilibrium thermodynamics. In: ICML (2015) Implicit Concept Removal of Diffusion Models 17 35. Song, Y., Sohl-Dickstein, J., Kingma, D.P., Kumar, A., Ermon, S., Poole, B.: Score- based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 (2020) 36. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023) 37. Van Den Oord, A., Vinyals, O., et al.: Neural discrete representation learning. In: NeurIPS (2017) 38. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I.: Attention is all you need. In: NeurIPS (2017) 39. Yang, Y., Gui, D., Yuan, Y., Ding, H., Hu, H., Chen, K.: Glyphcontrol: Glyph con- ditional control for visual text generation. arXiv preprint arXiv:2305.18259 (2023) 40. Zhang, E., Wang, K., Xu, X., Wang, Z., Shi, H.: Forget-me-not: Learning to forget in text-to-image diffusion models. arXiv preprint arXiv:2211.08332 (2023) 41. Zhang, Y., Hooi, B.: Hipa: Enabling one-step text-to-image diffusion models via high-frequency-promoting adaptation. arXiv preprint arXiv:2311.18158 (2023) 42. Zhang, Y., Hooi, B., Hong, L., Feng, J.: Self-supervised aggregation of diverse experts for test-agnostic long-tailed recognition. NeurIPS 35, 34077–34090 (2022) 43. Zhang, Y., Hooi, B., Hu, D., Liang, J., Feng, J.: Unleashing the power of con- trastive self-supervised visual models via contrast-regularized fine-tuning. NeurIPS 34, 29848–29860 (2021) 44. Zhang, Y., Zhou, D., Hooi, B., Wang, K., Feng, J.: Expanding small-scale datasets with guided imagination. In: NeurIPS (2023) 45. Zhili, L., Chen, K., Han, J., Lanqing, H., Xu, H., Li, Z., Kwok, J.: Task-customized masked autoencoder via mixture of cluster-conditional experts. In: ICLR (2023) 18 Z. Liu et al. A Details of Training and Datasets We perform erasure in two distinct settings. For Model Removal, we remove the watermark and unsafeness concepts from the original Stable Diffusion v1-5, and for Data Removal, we simulate the scenario where users fine-tune diffusion models with personalized datasets containing diverse implicit concepts. Detailed training information and dataset specifics for both settings are presented herein. A.1 Model Removal: Erasing from pre-trained SD In this setting, we identify text prompts likely to elicit the generation of images with implicit concepts and apply geometric erasure to these identified concepts. Watermark Removal. For Geom-Erasing training, 5000 text prompts in- ducing watermark-containing images are collected from ICD-Watermark. We use the watermark classifier model 5 to provide the concept existence condition and its classifier activation map for location information. The model is trained and only updates the added tokens representing concept existence and location. Dur- ing generation, we use the original text condition as positive guidance and the existence and location tokens as negative guidance. The results reported in the main paper are evaluated on the test dataset of ICD-Watermark. With such a method, Geom-Erasing is able to generate images without a watermark and keep other contents the same as not using learned tokens as negative prompts. See visualizations in the first two columns of Fig. A3. Toxicity Removal. Following the Inappropriate Image Prompts (I2P) [31] set- ting, 47030 images encompassing 7 toxicity categories are generated: hate, ha- rassment, violence, self-harm, sexual content, shocking images, illegal activity. NudeNet [26] and Q-16 classifier [32] are employed to identify toxicity, consider- ing both existence and location for the “sexual content” category using NudeNet, while only considering existence for other categories due to unavailable location information. The model is trained and only updates the added tokens. We apply the same generation strategy as ‘Watermark Removal’. Visualization can be seen in the last two columns of Fig. A3. A.2 Data Removal: Erasing from ICD In this scenario, we assemble three datasets (ICD) to emulate user fine-tuning of stable diffusion with personalized datasets harboring diverse implicit concepts. These concepts arise due to constraints in image sources and collection methods within specific downstream tasks. Further details on training and datasets are provided, with samples displayed in Fig. A2. 5 https://github.com/LAION-AI/LAION-5B-WatermarkDetection Implicit Concept Removal of Diffusion Models 19 ICD-QR (QR code Removal). Real QR codes to the Pokemon dataset [27]. The total dataset contains 802 image-text pairs, which is divided into two por- tions: 80% for fine-tuning, and the remaining 20% for testing. In the training subset, QR codes are pasted to 25% of the images, with QR code lengths varying from 1/4 to 1/2 of the image length, placed randomly, occasionally overlapping with the original content to resemble real-world scenarios. Importantly, test im- ages remain QR code-free for evaluation. To provide concept conditions and geometric information for our method and evaluation, a Faster-RCNN detector is trained using an open-source QR detection dataset6. We use the revised text conditions and fine-tune all the parameters of SD. Generation results can be seen in the first two rows of Fig. A4. ICD-Watermark (Watermark Removal). Images are collected from CC12M [5], amounting to 320k images, with half containing watermarks. A watermark recog- nition tool trained by LAION is employed to identify watermarked images from CC12M with a high confidence threshold of 0.9 to ensure accuracy. For prelim- inary experiments, subsets of 160k images with varying ratios of watermarked images are constructed. In other experiments, a consistent dataset of 80k images with watermarks and 80k images without watermarks is selected. To provide concept conditions, the watermark recognition tool is used, and for geometric information, the classifier activation map produced by the tool is employed, de- ciding areas of containing watermarks. Refer to the middle two rows of Fig. A4 for more generation results. ICD-Text (Text Removal). Text images are gathered from LAION [33]. The training dataset we used is provided by [39], known as LAION-Glyph. It com- prises 1M samples, with each image containing text. For the evaluation dataset, 2k text-free images are collected. To obtain geometric information and for eval- uation purposes, PP-OCRv3 [11] is used to detect text within the images. See the last two rows of Fig. A4 for visualization. B Why Implicit Concepts exists? To explore the reason and difficulty of this problem, we aim to elucidate the concept of watermarking, denoted as yim=‘watermark’. We first analyze the reason why implicit concept exists, and then we ascertain the impact of this implicit concept through following experiments. Implicit concept in SD stems from the implicit concept in data. The presence of implicit concepts in the Stable Diffusion (SD) model is rooted in implicit concepts present in the training data. We assume that these implicit concepts emerge because, during the training phase, they exist in the images without specific words in the text conditions expressing them. To understand 6 https://universe.roboflow.com/roboflow-qsmu6/qr-codes-detection 20 Z. Liu et al. 0 5 10 15 20 Training steps 10 20 30 40ICR ICR FID 7 8 9 10FID (a) Trade-off between ICR and FID. 0 25 50 75 100 ICR of fine-tuning data 10 20 30 40ICR ICR FID 7 8 9 10FID (b) Consistent trend between both. Fig. A1: The severity of implicit concept. In both figures, the left y-axis represents the ICR, while the right y-axis represents FID. (a) When tuning with a 50% concept ratio, the generated image ratio increases, while FID continues to improve during the tuning phase, suggesting a trade-off between image quality and the presence of implicit concepts. It is worth noting that the original SD model, represented by the 0-th training step, still generates over 10% watermarked images. (b) The ratio of the implicit concept is varied in the fine-tuning dataset. Higher ratios in the fine-tuning data correspond to higher ratios in the generated images, leading to poor image quality. This highlights the severity of the problem related to implicit concept presence. this, we conducted preliminary studies involving dataset manipulation to explore the causal relationship between training data characteristics and the severity of this issue. To emulate real-world scenarios, we curate a fine-tuning dataset, ICD-Watermark, from CC12M. In this dataset, 50% of the images contain wa- termarks, and the rest do not, with no “watermark” keyword present in text conditions. The SD model is subsequently fine-tuned with Eq. 1 to stimulate the training process. Evaluation is focuses on the implicit concept ratio (ICR, the ratio of images containing implicit concepts, defined in Sec. 5.1) and the Fréchet Inception Distance (FID) of the synthesized images. As can be seen in Fig. A1a, the training step 0 represents the original SD model without any fine- tuning. As fine-tuning progresses, FID typically decreases, but the proportion of watermarks in the generated images (ICR) steadily rises, indicating a trade-off between these two metrics. This indicates that models trained with datasets con- taining implicit concepts tend to unconsciously replicate these elements during generation. indicating such concepts are implicitly learned in the model. This poses a challenge as we aim to achieve a model that closely resembles the tar- get domain while being free of implicit concepts, especially when conducting personalized fine-tuning. Severity of implicit concepts. We further investigate it by examining the impact of varying watermark ratios in fine-tuning datasets. Multiple datasets are created with a consistent number of total images but different proportions of watermarked images. The results, depicted in Fig. A1b, reveal a consistent pattern. When the model is fine-tuned with a higher proportion of watermarked images, the generated images also exhibit a higher watermark ratio. Furthermore, this will also affect the generation quality of images as the FID score continues to be worse. Implicit Concept Removal of Diffusion Models 21 In summary, our preliminary experiments indicate that training with datasets containing implicit concepts markedly deteriorates the performance and intro- duces a considerable amount of unwanted concepts, motivating our proposed Geom-Erasing that can achieve both high generation quality and free of im- plicit concepts. C Additional Erasure visualizations We present visualizations of implicit concept erasure under two settings; refer to Fig. A3 for the first setting and Fig. A4 for the second setting. Notably, Geom-Erasing effectively removes “watermark” concepts in the original stable diffusion, including those challenging for human recognition. Intriguingly, for the “toxicity” concept, Geom-Erasing autonomously adds clothing to nude bodies, eliminating sexual content in the original images, while preserving other image contents. In the ICD erasure, specific implicit concepts are successfully eliminated, even within datasets containing undesired concepts. Both settings attest to the efficacy of Geom-Erasing. D More Discussion Limitation and future work. Geom-Erasing proposes a novel geometric-aware framework [9], originally designed for object detection data generation [15, 22], for the implicit concept removal in diffusion models. Although effective, Geom- Erasing still relies on external specialized concept detectors to provide reason- able geometric information, suggesting that utilization of more general localizers (e.g., the activation maps of generative pre-training [7,45] and contrastive learn- ing [6, 24, 42, 43]) would be an appealing future research direction. Moreover, it is also interesting to utilize the geometric controls to remove harmful concepts in large language models [8, 14, 36]. 22 Z. Liu et al. ICD-QR ICD-Watermark ICD-Text With QR Without QR With Watermark With Text Without Watermark Without Text Fig. A2: Image samples from our Implicit Concept Dataset (ICD). We provide both images with implicit conceptes Implicit Concept Removal of Diffusion Models 23 SD generate unintended watermarks Geom-Erasing Watermark concept is removed SD generate unintended toxicity Geom-Erasing Toxicity concept is removed censored censored censored censoredcensored censored censored censored Fig. A3: Erasing Implicit Concepts from SD. We successfully remove watermark and toxicity concepts from generated images while retaining other contents. Optimal viewing is recommended in color and at an enlarged scale. 24 Z. Liu et al. a cartoon character sitting on top of a green leaf A red fish with a gold crown on its head SD ESD FMN NP SLD Geom-Erasing a drawing of a fish with a horn on it's head daffodil flowers in a green metal vase, isolated over white background. double exposure with tree, green tree lungs of the city isolated on white fluffy dog close up of brown and black color 5v / 3 3v breadboard power supply from usb a stunning white bathroom 5 litre glass continuous brewing vintage style jar by kilner Fig. A4: Erasing implicit concept in ICD. The first group of images are fine-tuned on ICD-QR. The middle and the bottom are fine-tuned on ICD-watermark and ICD- Text, respectively.","libVersion":"0.3.2","langs":""}