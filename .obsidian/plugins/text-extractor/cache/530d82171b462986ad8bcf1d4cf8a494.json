{"path":"A-level Computer Science Notes/Steven/Pasted image 20241012042910.png","text":"Let us introduce the terminologics in our paper. Notably, we denote ¢ as the input description, commonly referred to as the textual prompt in text-to-image gencrative models. Additionally, we usc P (o represent the parameter prompt, which we will refer to as the “prompt” for brevity henceforth. Let e (21, ¢, 1) denote the output of the pre-trained foundation U-Net model parameterized by 0 at step ¢ given an input description ¢ and the latent vector from the previous step 2. Let ¢ (24, ¢, 1) denote the output of the sanitized model, parameterized by the to-be-finetuned parameters 0. For the sake of simplicity, we employ the notations ¢s(¢) and ¢, (). Let ¢ (¢, p) represent the output of the sanitized model given the input description ¢ and the parameter prompt p. The mechanism that allows us to inject the prompt p in to the cross-attention layer will be discussed later in Section It is worth noting that we can inject the same prompt into multiple cross-attention layers, thus <y () denotes the output of the entire model, not just a specific layer. Let ¢, € E denote a textual description in a sct of to-be-crased concepts E and ¢, represents a neutral or null concept, i.c., ‘a photo’ or . Knowledge Transfer. Initially, we initialize 0 — 0 (i.c., the pre-traincd foundation model) and Po. Atthe itcration &, we yicld &, and py and need to update for the next itcration. At this stage, we aim to find py 1 that is not too far from current py, and can resemble the undesirable concepts by minimizing the generation loss as . 2 B A K © Here, we note that in Eq. @as a result of the knowledge removal stage, the model ¢+ might have already weakened its knowledge of the undesirable concept, ic., ¢y () differs greatly from ¢o(c..). Therefore, matching ¢ (ce, p) with ca(c.), i.c., o ensure the fine-tuncd model together with the prompt can generate satisfactorily undesirable concepts, allowing the transfer of knowledge of crasing concepts to the prompt. We apply a one-step gradient descent to update the prompt as Piit=Pr = VoL (0,p), ©) where £, (0}, p) = Bece [Il‘uz (cerp) — €0 (cc) ||g] and 5 is the learning ratc. 5","libVersion":"0.3.2","langs":"eng"}