# 视频分析库文档

## 概述

这个库提供了使用大语言模型（LLMs）分析视频内容的功能。它可以提取实体、检测人物、分析他们在视频中的出现情况。该库设计灵活，可以通过通用接口与不同的大语言模型实现配合使用。

## 主要功能

- 从视频中提取实体
- 人物检测和跟踪
- 时间段分析
- 视频帧提取和边界框可视化
- 灵活的大语言模型集成

## 安装要求

库依赖以下组件：
- OpenCV (cv2)
- PIL (Python Imaging Library)
- 任何兼容的语言模型实现

## 快速开始

```python
from video_analysis_lib import VideoAnalyzer, LanguageModelInterface

# 初始化你的语言模型实现
model = YourLanguageModel()

# 创建分析器实例
analyzer = VideoAnalyzer(model, "path/to/video.mp4")

# 提取实体
entities = analyzer.extract_entities()

# 分析人物
if entities.get("PERSON"):
    detections = analyzer.analyze_persons(entities["PERSON"])
```

## 核心组件

### VideoAnalyzer

视频分析操作的主类。

#### 构造函数

```python
VideoAnalyzer(model: LanguageModelInterface, video_path: str, output_dir: str = "boundingbox_output")
```

参数：
- `model`：LanguageModelInterface 的实现
- `video_path`：视频文件路径
- `output_dir`：输出文件保存目录（默认："boundingbox_output"）

#### 方法

##### extract_entities()
从视频内容中提取各种实体。

返回值：
- `Dict[str, List[str]]`：按类型分类的实体字典：
  - DATE：日期或年份
  - ORG：组织机构
  - PERSON：人物或角色
  - FIELD：研究领域或行业
  - LOC：位置
  - OTHER：其他重要术语

##### analyze_persons(person_names: List[str])
分析指定人物在视频中的出现情况。

参数：
- `person_names`：要分析的人物名称列表

返回值：
- `Dict[str, PersonDetection]`：包含每个人物检测结果的字典

### LanguageModelInterface

必须实现的抽象基类，用于提供语言模型功能。

#### 必需方法

##### upload_file(path: str, mime_type: str) -> Any
将文件上传到语言模型服务。

参数：
- `path`：文件路径
- `mime_type`：文件的 MIME 类型

返回值：
- 特定于语言模型实现的文件对象

##### check_file_active(filename: str) -> Optional[Any]
检查文件在语言模型服务中是否处于活动状态。

参数：
- `filename`：要检查的文件名

返回值：
- 如果找到并且处于活动状态则返回文件对象，否则返回 None

##### call_model(prompt: str, file_data: Optional[Dict[str, Any]] = None) -> str
调用语言模型。

参数：
- `prompt`：要发送的提示文本
- `file_data`：可选的文件数据

返回值：
- 模型响应的字符串

## 辅助函数

### extract_frame(video_path: str, timestamp: int, output_dir: str) -> str
在指定时间戳从视频中提取帧。

参数：
- `video_path`：视频文件路径
- `timestamp`：时间（秒）
- `output_dir`：提取帧的保存目录

返回值：
- 保存的帧图像路径

### frame_to_image_data(frame_path: str) -> Dict[str, Any]
将帧图像转换为与大语言模型 API 兼容的格式。

参数：
- `frame_path`：帧图像路径

返回值：
- 包含图像数据和 MIME 类型的字典

### draw_bounding_box(frame_path: str, bounding_box: List[float], output_path: str) -> None
在帧图像上绘制边界框。

参数：
- `frame_path`：帧图像路径
- `bounding_box`：坐标 [ymin, xmin, ymax, xmax]
- `output_path`：注释图像的保存路径

### log_error(error: Exception, context: str = "") -> None
记录带有上下文信息的错误详情。

参数：
- `error`：异常对象
- `context`：可选的上下文字符串

## 数据类型

### TimeSegment（时间段）
```python
class TimeSegment(TypedDict):
    start_time: float  # 开始时间
    end_time: float    # 结束时间
```

### PersonSegments（人物片段）
```python
class PersonSegments(TypedDict):
    segments: List[TimeSegment]  # 时间段列表
```

### BoundingBoxCoords（边界框坐标）
```python
class BoundingBoxCoords(TypedDict):
    coordinates: List[float]  # [ymin, xmin, ymax, xmax]
```

### PersonDetection（人物检测）
```python
class PersonDetection(TypedDict):
    time_points: List[int]              # 时间点列表
    bounding_boxes: List[List[float]]   # 边界框列表
    frame_paths: List[str]              # 帧路径列表
    segments: List[TimeSegment]         # 时间段列表
```

### VideoAnalysisResult（视频分析结果）
```python
class VideoAnalysisResult(TypedDict):
    video_path: str                     # 视频路径
    timestamp: str                      # 时间戳
    entities: Dict[str, List[str]]      # 实体字典
    detections: Dict[str, PersonDetection]  # 检测结果字典
```

# 语言模型接口实现




# 视频分析库 - 语言模型实现指南

## LanguageModelInterface 介绍

`LanguageModelInterface` 是一个抽象基类，定义了与语言模型交互所需的核心方法。任何想要使用此视频分析库的开发者都需要实现这个接口。

## 实现要求

语言模型本质上是一个接口，如下所示。要求使用Video Analyzer之前要先实现一个实现调用语言模型的类，从```LanguageModelInterface``` 里面实现

### 1. 必须实现的方法

```python
class LanguageModelInterface(ABC):
    @abstractmethod
    def upload_file(self, path: str, mime_type: str) -> Any:
        """上传文件到语言模型服务"""
        pass

    @abstractmethod
    def check_file_active(self, filename: str) -> Optional[Any]:
        """检查文件是否处于活动状态"""
        pass

    @abstractmethod
    def call_model(self, prompt: str, file_data: Optional[Dict[str, Any]] = None) -> str:
        """调用语言模型"""
        pass
```

## Gemini模型实现示例详解 

以下是使用Google Gemini模型的完整实现示例，包含了所有必要的实现细节和最佳实践：

> [!NOTE]
> 这里是我用gemini API 的实现，如果是自己的语言模型调用方式不一样，只要保证输入输出对的上功能即可



```python
class GeminiModel(LanguageModelInterface):
    def __init__(self, api_key: str):
        # 配置API密钥
        genai.configure(api_key=api_key)
        
        # 配置速率限制
        self.min_delay = 65  # API调用最小间隔（秒）
        self.last_call_time = 0
        
        # 保存对话历史
        self.history = []
        
        # 生成配置
        self.generation_config = genai.GenerationConfig(
            temperature=0.4,    # 控制随机性（越低越确定）
            top_p=0.95,        # 核采样（越高越多样）
            top_k=40,          # Top-k采样（越高越多样）
            max_output_tokens=8192,  # 最大输出令牌数
        )

    def upload_file(self, path: str, mime_type: str) -> Any:
        """
        上传文件到Gemini服务
        
        关键点：
        1. 使用try-except捕获上传错误
        2. 打印上传状态供调试
        """
        try:
            print(f"正在上传文件: {path}")
            file = genai.upload_file(path, mime_type=mime_type)
            print(f"✓ 文件上传成功: {path}")
            return file
        except Exception as e:
            log_error(e, "文件上传")
            raise

    def check_file_active(self, filename: str) -> Optional[Any]:
        """
        检查文件是否处于活动状态
        
        关键点：
        1. 遍历所有文件查找目标文件
        2. 返回文件对象或None
        3. 错误处理确保稳定性
        """
        try:
            existing_files = genai.list_files()
            for file in existing_files:
                if file.display_name == filename:
                    print(f"✓ 找到文件 '{filename}'. 状态: {file.state.name}")
                    return file
            print(f"未找到文件 '{filename}'")
            return None
        except Exception as e:
            log_error(e, "检查文件状态")
            return None

    def call_model(self, prompt: str, file_data: Optional[Dict[str, Any]] = None) -> str:
        """
        调用Gemini模型
        
        关键点：
        1. 实现速率限制
        2. 维护对话历史
        3. 处理文件数据
        4. 清理响应文本
        5. 错误处理
        """
        try:
            # 实现速率限制
            current_time = time.time()
            time_since_last = current_time - self.last_call_time
            if time_since_last < self.min_delay:
                sleep_time = self.min_delay - time_since_last
                print(f"\n等待 {sleep_time:.1f} 秒后进行下一次API调用...")
                time.sleep(sleep_time)

            # 初始化模型
            model = genai.GenerativeModel("gemini-1.5-pro")
            
            # 准备内容
            content = []
            if file_data:
                content.append(file_data)
            content.append(prompt)

            # 添加用户消息到历史
            self.history.append({
                "role": "user",
                "parts": content,
            })

            # 调用模型并获取响应
            response = model.generate_content(
                self.history, 
                generation_config=self.generation_config
            )
            result = response.text
            self.last_call_time = time.time()

            # 添加模型响应到历史
            self.history.append({
                "role": "model",
                "parts": [result],
            })

            # 清理响应（移除JSON标记）
            result = result.replace('json', '').replace('```', '')
            return result
            
        except Exception as e:
            log_error(e, "调用模型")
            raise
```

## 实现注意事项

1. **速率限制处理**
   - 实现最小调用间隔（示例中为65秒）
   - 使用时间戳追踪上一次调用时间
   - 在需要时强制等待

2. **对话历史管理**
   - 维护对话历史列表
   - 记录用户和模型的所有消息
   - 保持对话上下文的连贯性

3. **生成参数配置**
   - temperature：控制输出随机性
   - top_p和top_k：控制输出多样性
   - max_output_tokens：控制输出长度

4. **错误处理**
   - 所有关键方法都包含错误处理
   - 使用专门的log_error函数记录详细信息
   - 错误信息包含具体的上下文

5. **文件处理**
   - 支持文件上传和状态检查
   - 处理各种MIME类型
   - 维护文件状态追踪

## 常见问题解决

1. **API限制处理**
```python
time_since_last = current_time - self.last_call_time
if time_since_last < self.min_delay:
    sleep_time = self.min_delay - time_since_last
    time.sleep(sleep_time)
```

2. **响应清理**
```python
# 移除可能影响JSON解析的标记
result = result.replace('json', '').replace('```', '')
```

3. **文件状态检查**
```python
for file in existing_files:
    if file.display_name == filename:
        return file
return None
```

## 测试建议

1. 测试API调用频率限制
2. 测试文件上传各种格式
3. 测试对话历史维护
4. 测试错误处理机制
5. 测试响应清理功能

## 性能优化建议

1. 实现请求队列管理
2. 添加响应缓存机制
3. 优化对话历史的内存使用
4. 实现并发请求处理
5. 添加重试机制




## 注意事项

- 库实现了 API 调用的速率限制和重试逻辑
- 结果以 JSON 格式保存以便进一步处理
- 提取的帧和边界框可视化保存在输出目录中
- 库处理各种错误情况并提供详细的日志记录
- 所有的实体提取都会确保不包含影片工作人员信息
- 实体名称只保留一种语言版本（优先选择原始语言）