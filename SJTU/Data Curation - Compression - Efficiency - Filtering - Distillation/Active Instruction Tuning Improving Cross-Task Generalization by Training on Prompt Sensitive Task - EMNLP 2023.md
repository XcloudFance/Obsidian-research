
- Prompt-uncertainty based methods

1. 提出新框架:主动指令微调(Active Instruction Tuning)

- 目标:主动识别信息量大的新任务,持续提升指令微调模型的跨任务泛化能力。
- 核心思想**:选择当前模型最不确定的任务进行训练,以最大程度提升模型性能。**
- **提示不确定性(Prompt Uncertainty)**
    - 定义:一种新的任务级不确定性度量,用于评估模型对任务指令扰动的敏感度。
    - 计算方法:  
        a. 对原始指令进行多次随机扰动(如随机删除词语)。  
        b. 比较模型在原始指令和扰动指令下的预测概率差异。  
        c. 对多个样本取平均,得到任务级的提示不确定性分数。  
        
- 优势:不需要任务的标注数据,可用于选择需要手动标注的新任务。

**对原始指令进行k次随机扰动(例如,随机删除20%的词)。**

1. 理论基础:

- 贝叶斯主动学习不一致性(BALD):论文将其思想从实例级扩展到任务级。
- 认知学习角度:如果模型无法稳定地将任务指令映射到特定的潜在概念,说明其对该任务的泛化能力有限。

1. 假设:

- 训练模型在提示不确定性高的任务上,可以提高模型将提示与特定潜在概念(任务)关联的能力。
- 这种训练策略应该能提高模型在未见指令上的零样本性能。