是否可以通过
- 机械数据过滤 - 去掉网址，特殊符号
- keybert 改良，获取核心词以及不核心词
- 构造输入输出数据集，引导模型去过滤内容
- 适当的augmentation - 重复instruction prompt？

## 问题
- 如何应对输入长度问题，每个任务基本上都是truncate后2000个token之类的大小
- 如果要对一个set进行打分，conditional？ - 或者gpt4 强相关
	- 现有做法1：gpt4监督一个过滤操作去训练T5模型
	- 现有做法2：One-shot prompt做accuracy前后Ratio
	- 现有做法3：也是one-shot prompt但是是perplexity做前后ratio
	- 
- 如果要对一个set进行过滤，我们是否一样可以先聚类贪心后对这个数据簇进行操作？
- 然后我们对set的大小放进去之后如何让模型可以意识到这是个高质量提取+改写操作？
	- prompt 显引导
	- gpt4 外部加强
- 
