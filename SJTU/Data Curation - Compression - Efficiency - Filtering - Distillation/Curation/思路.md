是否可以通过
- 机械数据过滤 - 去掉网址，特殊符号
- keybert 改良，获取核心词以及不核心词
- 构造输入输出数据集，引导模型去过滤内容
- 适当的augmentation - 重复instruction prompt？

## 问题
- 如何应对输入长度问题，每个任务基本上都是truncate后2000个token之类的大小
- 如果要对一个set进行打分，conditional？ - 或者gpt5 强相关
	- 现有做法1：gpt4监督一个过滤操作去训练T5模型
	- 现有做法2：One-shot prompt做accuracy前后Ratio
	- 现有做法3：也是one-shot prompt但是是perplexity做前后ratio
	- 
- 如果要对一个set进行过滤，我们是否一样可以先聚类贪心后对这个数据簇进行操作？
	- 感觉可行
	- sieve的做法是所有文本做成一个个2000个单词大小的，然后打分留下来snippet片段
	- 
- 然后我们对set的大小放进去之后如何让模型可以意识到这是个高质量提取+改写操作？
	- prompt 显引导
		- 也可以提取entity作为guidance表示这些要留下来（entity 倒排）
		- 还有就是可以multi-shot 问题的答案gpt4生成后引导模型去学习 - 也是entity based,但是别人是先用llama3.2生成一堆问题之后保存然后套entity [[BRIEF.pdf]], 然后答案直接当成输出
			- 但是问题并不是通用于所有文章的，或许可以让gpt4根据给出的entity去提问？
	- 额外模块判断关联度
[[Learning to Filter Context for Retrieval-Augmented Generation.pdf]]:
		- 词汇的overlap （sentence-level感觉可以，或者paragraph level）
		- 加了前后上下文后的互信息衡量
	
	- gpt4 外部加强

- 可以先机械化去重和清洗数据，后提取entity/keyword,后构造关系，判断冗余度信息或者toxicity信息（下手点），然后生成，打分过滤后再生成refine ？
- 要么就是重写内容quality生成，让gpt4 prompt-based监督 / 新操作生成有用的内容，让llama3.2 finetune后去逼近gpt4概括性能 - curriculum learning style
- 
- 
