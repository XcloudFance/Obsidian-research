这个方法的去重(deduplication)过程可以概括为以下几个关键步骤：

1. 训练阶段：

   a) 首先，使用KeyBERT为每个社交媒体文本提取关键词。
   b) 然后，训练一个生成模型（如T5）来预测这些关键词。训练只进行一个epoch，并应用时间维高斯噪声(TGN)来增加难度。
   c) 这个短暂的训练使模型能够学习预测常见（重复）文本的关键词，但对于独特的文本则难以准确预测。

2. 推理（去重）阶段：
   a) 使用训练好的模型为所有文本生成关键词。
   b) 比较生成的关键词与原始提取的关键词（目标关键词）。
   c) 如果生成的关键词与目标关键词匹配，则认为该文本是重复的。
   d) 移除被识别为重复的文本。

3. 去重的关键思想：

   - 重复或高度相似的文本在仅仅一个epoch的训练后更容易被准确预测关键词。
   - 独特的（非重复的）文本由于训练不足，难以准确预测关键词。
   - 这种差异使得模型能够区分重复和非重复文本。

4. 效率考虑：

   - 这种方法的复杂度为O(n)，其中n是文本数量。
   - 避免了传统去重方法中常见的成对比较，大大提高了效率。


